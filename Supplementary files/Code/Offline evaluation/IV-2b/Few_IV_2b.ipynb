{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "few_IV_2b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction"
      ],
      "metadata": {
        "id": "kyvFtg2noHWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run each cell one by one**"
      ],
      "metadata": {
        "id": "_JcttsieoHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start"
      ],
      "metadata": {
        "id": "1UsJVfmToHaT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqCkoRFQp_QT"
      },
      "source": [
        "1. Load the dataset from the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM4gPJFdp77y"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pprint, pickle\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id_1_train=\"13N5Il4V77Od7rK5ywff7YBWDD9PGJBdT\"\n",
        "id_1_evaluation=\"1RFAezNqq00h8lYs1f_kywJ0lDLhx-sKG\"\n",
        "\n",
        "id_2_train=\"17YZy5p42Bprj2Bo19lpH04iIBgf8J42l\"\n",
        "id_2_evaluation=\"13ZuGeuCSopUsPDMUz5TRZfaSuGnA_kZ7\"\n",
        "\n",
        "id_3_train=\"1mRJkhas7St256PhJPUI4TDQN2ENA2RnO\"\n",
        "id_3_evaluation=\"1fyk1WmHIk3V_XCDUch28DwWhHXFitogM\"\n",
        "\n",
        "id_4_train=\"1uEn_rGZMGLEcYuIfrXBcYroAOKTvkVRw\"\n",
        "id_4_evaluation=\"1jnp1LOgUcZhzcB7weaEQ3FTGk2gNGHcc\"\n",
        "\n",
        "\n",
        "id_5_train=\"1AGmGhS6pH5ED5v1Qc8RyJbHdybKG4G96\"\n",
        "id_5_evaluation=\"1IC74vwV5_IyBvBFfSpqIACzgYOI-2i4u\"\n",
        "\n",
        "id_6_train=\"1Td_zmiqkpKNQBwBje7pyJoRde9wUjABh\"\n",
        "id_6_evaluation=\"1XiJcjN1-Pe7-R89PugtFspWilF3QOlqi\"\n",
        "\n",
        "id_7_train=\"1dujTQPIGDBSozlbXt_hJj_qKIftxWVka\"\n",
        "id_7_evaluation=\"1LniXihHiqx1PSlvmJXu20LaOeXCjBmeQ\"\n",
        "\n",
        "\n",
        "id_8_train=\"1T66t4HpF1XTB6QNL9ZdwILWGU5sEmf09\"\n",
        "id_8_evaluation=\"1lxZVBtjtdzF7aZPx4oh2265m-049XgnO\"\n",
        "\n",
        "id_9_train=\"1zGIpgC3RNRb1qF8t-id3IGtvd92C7IQV\"\n",
        "id_9_evaluation=\"1guGz6wBBwzTrRNQGCvP-ar2GuI8ZQWe7\"\n",
        "\n",
        "def load(id_train,id_evaluation,subject):\n",
        "  downloaded = drive.CreateFile({'id':id_train}) \n",
        "  downloaded.GetContentFile('B0'+str(subject)+'T.mat')\n",
        "  downloaded = drive.CreateFile({'id':id_evaluation}) \n",
        "  downloaded.GetContentFile('B0'+str(subject)+'E.mat')\n",
        "\n",
        "load(id_1_train,id_1_evaluation,1)\n",
        "load(id_2_train,id_2_evaluation,2)\n",
        "load(id_3_train,id_3_evaluation,3)\n",
        "\n",
        "load(id_4_train,id_4_evaluation,4)\n",
        "load(id_5_train,id_5_evaluation,5)\n",
        "load(id_6_train,id_6_evaluation,6)\n",
        "\n",
        "load(id_7_train,id_7_evaluation,7)\n",
        "load(id_8_train,id_8_evaluation,8)\n",
        "load(id_9_train,id_9_evaluation,9)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n8mWmL1rAdM"
      },
      "source": [
        "2. Load package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDVvdu4vsAyU"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd.function import Function\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.decomposition import PCA\n",
        "import torch.utils.data as Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqWvTAmZq8l9"
      },
      "source": [
        "3. Convert the data in mat format into Numpy array\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCH_AOprrIzF"
      },
      "source": [
        "def load_all_data (crossValidation, data_path): \n",
        "\n",
        "    big_X_train, big_y_train, big_X_test, big_y_test = [None]*9, [None]*9, [None]*9, [None]*9\n",
        "    for subject in range (0,9):\n",
        "        path = data_path+'s' + str(subject+1) + '/'\n",
        "        big_X_train[subject], big_y_train[subject] = get_data(subject+1, True ,path)\n",
        "        big_X_test[subject], big_y_test[subject] = get_data(subject+1, False ,path)\n",
        "    \n",
        "    return big_X_train, big_y_train, big_X_test, big_y_test\n",
        "\n",
        "def get_data(subject,training,path, highpass = False):\n",
        "\t'''\tLoads the dataset 2a of the BCI Competition IV\n",
        "\tavailable on http://bnci-horizon-2020.eu/database/data-sets\n",
        "\n",
        "\tKeyword arguments:\n",
        "\tsubject -- number of subject in [1, .. ,9]\n",
        "\ttraining -- if True, load training data\n",
        "\t\t\t\tif False, load testing data\n",
        "\t\n",
        "\tReturn:\tdata_return \tnumpy matrix \tsize = NO_valid_trial x 22 x 1750\n",
        "\t\t\tclass_return \tnumpy matrix \tsize = NO_valid_trial\n",
        "\t'''\n",
        "\tNO_channels = 3\n",
        "\tNO_tests = 120+120+160\t\n",
        "\tWindow_Length = 7*250 \n",
        "\n",
        "\tclass_return = np.zeros(NO_tests)\n",
        "\tdata_return = np.zeros((NO_tests,NO_channels,Window_Length))\n",
        "\n",
        "\tNO_valid_trial = 0\n",
        "\tif training:\n",
        "\t\ta = sio.loadmat(path+'B0'+str(subject)+'T.mat')\n",
        "\telse:\n",
        "\t\ta = sio.loadmat(path+'B0'+str(subject)+'E.mat')\n",
        "\ta_data = a['data']\n",
        "\tfor ii in range(0,a_data.size):\n",
        "\t\ta_data1 = a_data[0,ii]\n",
        "\t\ta_data2= [a_data1[0,0]]\n",
        "\t\ta_data3= a_data2[0]\n",
        "\t\ta_X \t\t= a_data3[0]\n",
        "\t\ta_trial \t= a_data3[1]\n",
        "\t\ta_y \t\t= a_data3[2]\n",
        "\t\ta_fs \t\t= a_data3[3]\n",
        "\t\ta_classes \t= a_data3[4]\n",
        "\t\ta_artifacts = a_data3[5]\n",
        "\t\ta_gender \t= a_data3[6]\n",
        "\t\ta_age \t\t= a_data3[7]\n",
        "\n",
        "\t\tfor trial in range(0,a_trial.size):\n",
        "\t\t\tif(a_artifacts[trial]==0):\n",
        "\t\t\t\tdata_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial]):(int(a_trial[trial])+Window_Length),:3])\n",
        "\t\t\t\tclass_return[NO_valid_trial] = int(a_y[trial])\n",
        "\t\t\t\tNO_valid_trial +=1\n",
        "\n",
        "\n",
        "\treturn data_return[0:NO_valid_trial,:,:], class_return[0:NO_valid_trial]\n",
        "\n",
        "def prepare_features(path,subject,crossValidation=False):\n",
        "    fs = 250 \n",
        "    t1 = int(3*fs)\n",
        "    t2 = int(7*fs)\n",
        "    T = t2-t1\n",
        "    X_train, y_train = get_data(subject+1,True,path)\n",
        "    if crossValidation:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=0)\n",
        "    else:\n",
        "        X_test, y_test = get_data(subject+1,False,path)\n",
        "\n",
        "    # prepare training data \t\n",
        "    N_tr,N_ch,_ =X_train.shape \n",
        "    X_train = X_train[:,:,t1:t2].reshape(N_tr,1,N_ch,T)\n",
        "    y_train_onehot = (y_train-1).astype(int)\n",
        "    y_train_onehot = to_categorical(y_train_onehot)\n",
        "    # prepare testing data \n",
        "    N_test,N_ch,_ =X_test.shape \n",
        "    X_test = X_test[:,:,t1:t2].reshape(N_test,1,N_ch,T)\n",
        "    y_test_onehot = (y_test-1).astype(int)\n",
        "    y_test_onehot = to_categorical(y_test_onehot)\t\n",
        "    return X_train,y_train,y_train_onehot,X_test,y_test,y_test_onehot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IsVNNr0t1P5"
      },
      "source": [
        "5. Modified EEGNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeNZy3I666py"
      },
      "source": [
        "class Constrainedlinear(nn.Linear):\n",
        "    def _max_norm(self,w,max_val=0.25,eps=1e-8):\n",
        "        norm = w.norm(2, dim=1, keepdim=True)\n",
        "        desired = torch.clamp(norm, 0, max_val)\n",
        "        return w * (desired / (eps + norm))\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, self._max_norm(self.weight),self.bias)\n",
        "\n",
        "\n",
        "class Constrainedlinear111(nn.Linear):\n",
        "    def _max_norm(self,w,max_val=0.5,eps=1e-8):\n",
        "        norm = w.norm(2, dim=1, keepdim=True)\n",
        "        desired = torch.clamp(norm, 0, max_val)\n",
        "        return w * (desired / (eps + norm))\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, self._max_norm(self.weight),self.bias)\n",
        "\n",
        "\n",
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, classes_num):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.numC=3\n",
        "\n",
        "        self.drop_out = 0.2\n",
        "        \n",
        "        self.block_1 = nn.Sequential(\n",
        "            # Pads the input tensor boundaries with zero\n",
        "            # left, right, up, bottom\n",
        "            nn.ZeroPad2d((15, 16, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,          # input shape (1, C, T)\n",
        "                out_channels=8,         # num_filters\n",
        "                kernel_size=(1, 32),    # filter size\n",
        "                bias=False\n",
        "            ),                          # output shape (8, C, T)\n",
        "            nn.BatchNorm2d(8)           # output shape (8, C, T)\n",
        "        )\n",
        "        \n",
        "        # block 2 and 3 are implementations of Depthwise Convolution and Separable Convolution\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=8,          # input shape (8, C, T)\n",
        "                out_channels=16,        # num_filters\n",
        "                kernel_size=(self.numC, 1),    # filter size\n",
        "                groups=8,\n",
        "                bias=False\n",
        "            ),                          # output shape (16, 1, T)\n",
        "            nn.BatchNorm2d(16),         # output shape (16, 1, T)\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),       # output shape (16, 1, T//4)\n",
        "            nn.Dropout(self.drop_out)   # output shape (16, 1, T//4)\n",
        "        )\n",
        "        \n",
        "        self.block_3 = nn.Sequential(\n",
        "            nn.ZeroPad2d((7, 8, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "               in_channels=16,          # input shape (16, 1, T//4)\n",
        "               out_channels=16,         # num_filters\n",
        "               kernel_size=(1, 16),     # filter size\n",
        "               groups=16,\n",
        "               bias=False\n",
        "            ),                          # output shape (16, 1, T//4)\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,         # input shape (16, 1, T//4)\n",
        "                out_channels=16,        # num_filters\n",
        "                kernel_size=(1, 1),     # filter size\n",
        "                bias=False\n",
        "            ),                          # output shape (16, 1, T//4)\n",
        "            nn.BatchNorm2d(16),         # output shape (16, 1, T//4)\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),       # output shape (16, 1, T//32)\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.preluip1 = nn.PReLU()\n",
        "        self.out = Constrainedlinear((16 * 15), classes_num)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.out(x)\n",
        "        return F.log_softmax(x, dim=1) #x   # return x for visualization\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYuttlug_1wQ"
      },
      "source": [
        "8. Train and Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(Subject_number):\n",
        "  #Prepare the raw feature data for training and testing#\n",
        "  #You can change the \"Subject_number\" (0-8 corresponding to B01-B09, respectively) to try training and testing between different subjects\n",
        "  Subject_number=Subject_number\n",
        "  BATCH_SIZE = 10\n",
        "  x_train,y_train,y_train_onehot,x_test,y_test,y_test_onehot = prepare_features('',Subject_number,False)\n",
        "  total_x=np.vstack((x_train,x_test))\n",
        "  total_y=np.hstack((y_train,y_test))\n",
        "  # total_y_onehot=np.vstack((y_train_onehot,y_test_onehot))\n",
        "  index1=np.where(total_y == 1)[0]\n",
        "  index2=np.where(total_y == 2)[0]\n",
        "  choice1=np.random.choice(index1,10,replace=False)\n",
        "  choice2=np.random.choice(index2,10,replace=False)\n",
        "  choice_total=np.hstack((choice1,choice2))\n",
        "  x_train=total_x[choice_total]\n",
        "  x_test= np.delete(total_x, choice_total,0)\n",
        "  y_train=total_y[choice_total]\n",
        "  y_test=np.delete(total_y, choice_total)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  x_train=torch.from_numpy(x_train)\n",
        "  y_train=torch.from_numpy(y_train-1)\n",
        "  x_test=torch.from_numpy(x_test)\n",
        "  y_test=torch.from_numpy(y_test-1)\n",
        "  x_train=x_train.float()\n",
        "  x_test=x_test.float()\n",
        "  y_train=y_train.long()\n",
        "  y_test=y_test.long()\n",
        "  train_dataset=Data.TensorDataset(x_train,y_train)\n",
        "  val_dataset=Data.TensorDataset(x_test,y_test)\n",
        "\n",
        "  #Construct the training Loader\n",
        "  train_loader= Data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "  test_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  eeg_net = EEGNet(classes_num=2).to(device)\n",
        "\n",
        "  # summary(eeg_net,(1, 3, 1000))\n",
        "\n",
        "  nllloss = nn.NLLLoss().to(device) #CrossEntropyLoss = log_softmax + NLLLoss\n",
        "\n",
        "# optimzer4nn\n",
        "  optimizer4nn = optim.Adam(eeg_net.parameters(),lr=0.001)\n",
        "\n",
        "  #Define the number of epochs\n",
        "  EPOCH=100\n",
        "\n",
        "#Define the device\n",
        "  DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  for epoch in range(EPOCH):\n",
        "    loss_total=[]\n",
        "\n",
        "  #Update x_i using the gradient descent\n",
        "    for step, (b_x, b_y) in enumerate(train_loader):\n",
        "      b_x, b_y = b_x.to(DEVICE), b_y.to(DEVICE)\n",
        "      output = eeg_net(b_x)\n",
        "      loss = nllloss(output,b_y) \n",
        "      loss_total.append(loss.item())\n",
        "      optimizer4nn.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer4nn.step()\n",
        "    if (epoch+1)%100==0:\n",
        "      print('Epoch: ', epoch+1, '| train loss: %.4f' % (np.mean(loss_total)),len(loss_total))\n",
        " \n",
        "  eeg_net.eval()\n",
        "  train_out=eeg_net(x_train.to(DEVICE))\n",
        "  trpre_y = torch.max(train_out.cpu(), 1)[1].data.numpy()\n",
        "  tra_acc = float((trpre_y == y_train.data.numpy()).astype(int).sum()) / float(y_train.size(0))\n",
        "  print(\"Subject \"+str(Subject_number+1)+' train accuracy: %.4f' % tra_acc)\n",
        "\n",
        "\n",
        "  test_out = eeg_net(x_test.to(DEVICE))\n",
        "  pred_y = torch.max(test_out.cpu(), 1)[1].data.numpy()\n",
        "  accuracy = float((pred_y == y_test.data.numpy()).astype(int).sum()) / float(y_test.size(0))\n",
        "  print(\"Subject \"+str(Subject_number+1)+' test accuracy: %.4f' % accuracy)\n",
        "  print('')\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "mPSZ9e2gCYSK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the subject number 0-8 corrsponding to subject B01-B09; Subject_number=0\n",
        "Subject_number=2\n",
        "print(\"Subject:\",Subject_number+1)\n",
        "train(Subject_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCjvJ8EKkUUQ",
        "outputId": "e338fe79-fa99-4410-d217-33e3b0fd76fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: 3\n",
            "Epoch:  100 | train loss: 0.2615 2\n",
            "Subject 3 train accuracy: 1.0000\n",
            "Subject 3 test accuracy: 0.6107\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6106719367588933"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z7X_BYTwlgV9"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}