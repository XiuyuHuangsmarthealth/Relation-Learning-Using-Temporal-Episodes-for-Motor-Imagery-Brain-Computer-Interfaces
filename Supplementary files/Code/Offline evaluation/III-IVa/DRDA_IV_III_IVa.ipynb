{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "III_adversial_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction"
      ],
      "metadata": {
        "id": "04XNDxwZVtLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run each cell one by one**"
      ],
      "metadata": {
        "id": "1onxBHNEVtOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "7p7NTFpzfjay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dUwchsKoehNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee092b2a-86db-457a-bb99-36dc787f052a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.0.3-py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.0.3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install mne\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import mne\n",
        "def indexget(total,select):\n",
        "  return [i for i, e in enumerate(total) if e in select]\n",
        "\n",
        "\n",
        "\n",
        "def inputmat(fp1,fp2,fp3):\n",
        "    \"\"\"load .mat file and return m as a dict\"\"\"\n",
        "    mat = sio.loadmat(fp1, squeeze_me=True)\n",
        "    label_mat=sio.loadmat(fp2, squeeze_me=True)\n",
        "    m = {}  # create a dict\n",
        "\n",
        "    # Numpy array of size channel_num * points.\n",
        "    select_channel=fp3\n",
        "    channelindex= indexget(mat['nfo']['clab'][True][0],select_channel)\n",
        "    m['ch_names'] = mat['nfo']['clab'][True][0][channelindex]\n",
        "    \n",
        "\n",
        "\n",
        "    m['data'] = mat['cnt'].T[channelindex]\n",
        "    m['freq'] = mat['nfo']['fs'][True][0]  # Sampling frequency\n",
        "\n",
        "    # channel names are necessary information for creating a rawArray.\n",
        "\n",
        "\n",
        "    # Position of channels\n",
        "    m['electrode_x'] = mat['nfo']['xpos'][True][0]\n",
        "    m['electrode_y'] = mat['nfo']['ypos'][True][0]\n",
        "\n",
        "    # find trials and its data\n",
        "    m['cue'] = mat['mrk']['pos'][True][0]  # time of cue\n",
        "    m['labels'] = label_mat['true_y']  \n",
        "    # m['labels'] = np.nan_to_num(mat['mrk']['y'][True][0]).astype(int)  # convert NaN to 0\n",
        "    m['test_idx'] = len(label_mat['test_idx'])\n",
        "    m['n_trials'] = len(m['labels'])  # Number of the total useful trials\n",
        "    return m\n",
        "\n",
        "\n",
        "def creatEventsArray(fp1,fp2,fp3):\n",
        "    \"\"\"Create events array. The second column default to zero.\"\"\"\n",
        "    m = inputmat(fp1,fp2,fp3)\n",
        "    events = np.zeros((m['n_trials'], 3), int)\n",
        "    events[:, 0] = m['cue'][:m['n_trials']]  # The first column is the sample number of the event.\n",
        "    events[:, 2] = m['labels'][:m['n_trials']]  # The third column is the new event value.\n",
        "    return events, m['labels']\n",
        "\n",
        "\n",
        "def creatRawArray(fp1,fp2,fp3):\n",
        "    \"\"\"Create a mne.io.RawArray object, data: array, shape (n_channels, n_times)\"\"\"\n",
        "    m = inputmat(fp1,fp2,fp3)\n",
        "    ch_names = m['ch_names'].tolist()\n",
        "    info = mne.create_info(ch_names, m['freq'], 'eeg')  # Create info for raw\n",
        "    raw = mne.io.RawArray(m['data'], info, first_samp=0, copy='auto', verbose=None)\n",
        "    return raw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Package"
      ],
      "metadata": {
        "id": "5GVQ8tbHfnUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd.function import Function\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.decomposition import PCA\n",
        "import torch.utils.data as Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n"
      ],
      "metadata": {
        "id": "Mgj4QFzmfo-p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(__doc__)\n",
        "\n",
        "fp = {\n",
        "    'aa': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/data_set_IVa_aa.mat',\n",
        "    'al': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/data_set_IVa_al.mat',\n",
        "    'av': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/data_set_IVa_av.mat',\n",
        "    'aw': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/data_set_IVa_aw.mat',\n",
        "    'ay': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/data_set_IVa_ay.mat',\n",
        "}\n",
        "\n",
        "\n",
        "fplabel={\n",
        "    'aa': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/true_labels_aa.mat',\n",
        "    'al': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/true_labels_al.mat',\n",
        "    'av': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/true_labels_av.mat',\n",
        "    'aw': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/true_labels_aw.mat',\n",
        "    'ay': '/content/drive/MyDrive/fewshotonlineBCI/CompetitionIII_IVa/true_labels_ay.mat',\n",
        "\n",
        "}\n",
        "\n",
        "channel_set=['C1',  'C3',  'Cz',  'C2',  'C4',  'CFC3',  'CFC4','CFC5',  'CFC6',  'CCP3', \n",
        "             'CCP4',  'CCP5',  'CCP6',  'T7',  'T8',  'P3',  'Pz',  'P4']\n",
        "pick_chan = {\n",
        "    'aa':  channel_set,\n",
        "    'al':  channel_set,\n",
        "    'av':  channel_set,\n",
        "    'aw':  channel_set,\n",
        "    'ay':  channel_set,\n",
        "\n",
        "}\n",
        "\n",
        "low_freq, high_freq = 7., 30.\n",
        "tmin, tmax = 0., 3.5\n",
        "# event_id\n",
        "event_id = {'right': 1, 'foot': 2}"
      ],
      "metadata": {
        "id": "Bf_n8f-Ufw0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cd30e6-3842-4c92-9857-7f2d8e951c20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing the data"
      ],
      "metadata": {
        "id": "fRL7SeGaWJGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from mne.decoding import CSP\n",
        "from mne.channels import read_layout\n",
        "\n",
        "\n",
        "\n",
        "def cal_acc(pred,real):\n",
        "  return [1 if pred[j]==real[j] else 0 for j in range(len(real))]\n",
        "\n",
        "def getdata_label(a,b,c):\n",
        "  mat_dic=inputmat(a,b,c)\n",
        "  raw = creatRawArray(a,b,c)\n",
        "  events, labels = creatEventsArray(a,b,c)\n",
        "\n",
        "\n",
        "    # Apply band-pass filter\n",
        "  raw.filter(low_freq, high_freq, fir_design='firwin', skip_by_annotation='edge')\n",
        "\n",
        "    # event_train = eventsTrain(fp[f])\n",
        "  epochs = mne.Epochs(raw, events=events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True,\n",
        "                        verbose=False)\n",
        "\n",
        "  epochs_train = epochs.copy().crop(tmin=0.5, tmax=2.5)\n",
        "  labels = epochs.events[:, -1]\n",
        "\n",
        "    # # Define a monte-carlo cross-validation generator (reduce variance):\n",
        "  epochs_data= epochs_train.get_data()\n",
        "  return epochs_data,labels,mat_dic['test_idx']\n",
        "\n",
        "intial_dic={}\n",
        "\n",
        "total_length=280\n",
        "train_num=10\n",
        "test_num=10\n",
        "\n",
        "for f,fla,cs in zip(fp,fplabel,pick_chan):\n",
        "    x,y,testix=getdata_label(fp[f],fplabel[fla],pick_chan[cs])\n",
        "\n",
        "    intial_dic[f]=[x,y]\n",
        "    # # Assemble a classifier\n",
        "    # \n",
        "    # csp = CSP(n_components=len(epochs.ch_names), reg=None, log=True, norm_trace=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tiQUkxff3bLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d7be87-5897-4e93-f3bc-ebdee8897153"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating RawArray with float64 data, n_channels=18, n_times=298458\n",
            "    Range : 0 ... 298457 =      0.000 ...  2984.570 secs\n",
            "Ready.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 7 - 30 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 7.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
            "- Upper passband edge: 30.00 Hz\n",
            "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
            "- Filter length: 165 samples (1.650 sec)\n",
            "\n",
            "Creating RawArray with float64 data, n_channels=18, n_times=283574\n",
            "    Range : 0 ... 283573 =      0.000 ...  2835.730 secs\n",
            "Ready.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 7 - 30 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 7.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
            "- Upper passband edge: 30.00 Hz\n",
            "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
            "- Filter length: 165 samples (1.650 sec)\n",
            "\n",
            "Creating RawArray with float64 data, n_channels=18, n_times=283042\n",
            "    Range : 0 ... 283041 =      0.000 ...  2830.410 secs\n",
            "Ready.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 7 - 30 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 7.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
            "- Upper passband edge: 30.00 Hz\n",
            "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
            "- Filter length: 165 samples (1.650 sec)\n",
            "\n",
            "Creating RawArray with float64 data, n_channels=18, n_times=282838\n",
            "    Range : 0 ... 282837 =      0.000 ...  2828.370 secs\n",
            "Ready.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 7 - 30 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 7.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
            "- Upper passband edge: 30.00 Hz\n",
            "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
            "- Filter length: 165 samples (1.650 sec)\n",
            "\n",
            "Creating RawArray with float64 data, n_channels=18, n_times=283562\n",
            "    Range : 0 ... 283561 =      0.000 ...  2835.610 secs\n",
            "Ready.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 7 - 30 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 7.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
            "- Upper passband edge: 30.00 Hz\n",
            "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
            "- Filter length: 165 samples (1.650 sec)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic=[]\n",
        "str_list=['aa','al','av','aw','ay']\n",
        "\n",
        "\n",
        "for i in str_list:\n",
        "  temp=[]\n",
        "  x,y=intial_dic[i]\n",
        "  x=x.reshape(x.shape[0],1,x.shape[1],-1)\n",
        "\n",
        "  y=y-1\n",
        "  temp.append(x)\n",
        "  temp.append(y)\n",
        "\n",
        "  dic.append(temp)"
      ],
      "metadata": {
        "id": "i2UPp4vp0L36"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Load"
      ],
      "metadata": {
        "id": "flRSR5iMf4TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(Subject_number):\n",
        "\n",
        "#Prepare the raw feature data for training and testing#\n",
        "  #You can change the \"Subject_number\" (0-8 corresponding to B01-B09, respectively) to try training and testing between different subjects\n",
        "  Subject_number=Subject_number\n",
        "  BATCH_SIZE = 64\n",
        "  total_x,total_y=dic[Subject_number][0],dic[Subject_number][1]\n",
        "  hyperparameter=10\n",
        "  # total_y_onehot=np.vstack((y_train_onehot,y_test_onehot))\n",
        "  index1=np.where(total_y == 0)[0]\n",
        "  index2=np.where(total_y == 1)[0]\n",
        "  choice1=np.random.choice(index1,hyperparameter,replace=False)\n",
        "  choice2=np.random.choice(index2,hyperparameter,replace=False)\n",
        "  choice_total=np.hstack((choice1,choice2))\n",
        "  xxxtest= np.delete(total_x, choice_total,0)\n",
        "  yyytest=np.delete(total_y, choice_total)\n",
        "\n",
        "\n",
        "  target_x=total_x[choice_total]\n",
        "  target_y=total_y[choice_total]\n",
        "\n",
        "\n",
        "\n",
        "  total_x_train=[]\n",
        "  total_y_train=[]\n",
        "  full_subjectnum=[0,1,2,3,4]\n",
        "  full_subjectnum.remove(Subject_number)\n",
        "  for train_subject in full_subjectnum:\n",
        "    x_train,y_train = dic[train_subject][0],dic[train_subject][1]\n",
        "\n",
        "    if len(total_x_train)==0:\n",
        "      total_x_train=x_train\n",
        "      total_y_train=y_train\n",
        "    else:\n",
        "      total_x_train=np.vstack((total_x_train,x_train))\n",
        "      total_y_train=np.hstack((total_y_train,y_train))\n",
        "\n",
        "  x_train=total_x_train\n",
        "  y_train=total_y_train\n",
        "\n",
        "\n",
        "  x_test=xxxtest\n",
        "  y_test=yyytest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  target_x=torch.from_numpy(target_x)\n",
        "  target_y=torch.from_numpy(target_y)\n",
        "  target_x=target_x.float()\n",
        "  target_y=target_y.long()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  x_train=torch.from_numpy(x_train)\n",
        "  y_train=torch.from_numpy(y_train)\n",
        "  x_test=torch.from_numpy(x_test)\n",
        "  y_test=torch.from_numpy(y_test)\n",
        "  x_train=x_train.float()\n",
        "  x_test=x_test.float()\n",
        "  y_train=y_train.long()\n",
        "  y_test=y_test.long()\n",
        "  source_dataset=Data.TensorDataset(x_train,y_train)\n",
        "  target_dataset=Data.TensorDataset(target_x,target_y)\n",
        "  val_dataset=Data.TensorDataset(x_test,y_test)\n",
        "\n",
        "\n",
        "    \n",
        "  source_loader= Data.DataLoader(source_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "  target_loader = Data.DataLoader(target_dataset, batch_size=2, shuffle=True, num_workers=2)\n",
        "  test_loader = Data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "  return source_loader,target_loader,test_loader"
      ],
      "metadata": {
        "id": "p2dboIeOf33H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network"
      ],
      "metadata": {
        "id": "IowgK2pVmf6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "\n",
        "class Constrainedlinear(nn.Linear):\n",
        "    def _max_norm(self,w,max_val=0.25,eps=1e-8):\n",
        "        norm = w.norm(2, dim=1, keepdim=True)\n",
        "        desired = torch.clamp(norm, 0, max_val)\n",
        "        return w * (desired / (eps + norm))\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, self._max_norm(self.weight),self.bias)\n"
      ],
      "metadata": {
        "id": "MeV0V71jncUT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self,classes_num):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.numC=18\n",
        "\n",
        "        self.drop_out = 0.2\n",
        "        \n",
        "        self.block_1 = nn.Sequential(\n",
        "            # Pads the input tensor boundaries with zero\n",
        "            # left, right, up, bottom\n",
        "            nn.ZeroPad2d((15, 16, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,          # input shape (1, C, T)\n",
        "                out_channels=8,         # num_filters\n",
        "                kernel_size=(1, 32),    # filter size\n",
        "                bias=False\n",
        "            ),                          # output shape (8, C, T)\n",
        "            nn.BatchNorm2d(8)           # output shape (8, C, T)\n",
        "        )\n",
        "        \n",
        "        # block 2 and 3 are implementations of Depthwise Convolution and Separable Convolution\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=8,          # input shape (8, C, T)\n",
        "                out_channels=16,        # num_filters\n",
        "                kernel_size=(self.numC, 1),    # filter size\n",
        "                groups=8,\n",
        "                bias=False\n",
        "            ),                          # output shape (16, 1, T)\n",
        "            nn.BatchNorm2d(16),         # output shape (16, 1, T)\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),       # output shape (16, 1, T//4)\n",
        "            nn.Dropout(self.drop_out)   # output shape (16, 1, T//4)\n",
        "        )\n",
        "        \n",
        "        self.block_3 = nn.Sequential(\n",
        "            nn.ZeroPad2d((7, 8, 0, 0)),\n",
        "            nn.Conv2d(\n",
        "               in_channels=16,          # input shape (16, 1, T//4)\n",
        "               out_channels=16,         # num_filters\n",
        "               kernel_size=(1, 16),     # filter size\n",
        "               groups=16,\n",
        "               bias=False\n",
        "            ),                          # output shape (16, 1, T//4)\n",
        "            nn.Conv2d(\n",
        "                in_channels=16,         # input shape (16, 1, T//4)\n",
        "                out_channels=16,        # num_filters\n",
        "                kernel_size=(1, 1),     # filter size\n",
        "                bias=False\n",
        "            ),                          # output shape (16, 1, T//4)\n",
        "            nn.BatchNorm2d(16),         # output shape (16, 1, T//4)\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, 8)),       # output shape (16, 1, T//32)\n",
        "            nn.Dropout(self.drop_out)\n",
        "        )\n",
        "\n",
        "        self.class_classifier = nn.Sequential()\n",
        "        self.class_classifier.add_module('c_fc1',  Constrainedlinear(48, classes_num))\n",
        "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.domain_classifier = nn.Sequential()\n",
        "        self.domain_classifier.add_module('d_fc1', nn.Linear(48, 100))\n",
        "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
        "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
        "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
        "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
        "\n",
        "    def forward(self, x, alpha):\n",
        "\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        \n",
        "        feature = x.view(x.size(0), -1)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.class_classifier(feature)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return feature, class_output, domain_output"
      ],
      "metadata": {
        "id": "uxGArLbQmjZ6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Center loss"
      ],
      "metadata": {
        "id": "NGZiRSZGJ8I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CenterLoss(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim, size_average=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.centers = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
        "        self.centerlossfunc = CenterlossFunc.apply\n",
        "        self.feat_dim = feat_dim\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, label, feat):\n",
        "        batch_size = feat.size(0)\n",
        "        feat = feat.view(batch_size, -1)\n",
        "        # To check the dim of centers and features\n",
        "        if feat.size(1) != self.feat_dim:\n",
        "            raise ValueError(\"Center's dim: {0} should be equal to input feature's \\\n",
        "                            dim: {1}\".format(self.feat_dim,feat.size(1)))\n",
        "        batch_size_tensor = feat.new_empty(1).fill_(batch_size if self.size_average else 1)\n",
        "        loss = self.centerlossfunc(feat, label, self.centers, batch_size_tensor)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CenterlossFunc(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, feature, label, centers, batch_size):\n",
        "        ctx.save_for_backward(feature, label, centers, batch_size)\n",
        "        centers_batch = centers.index_select(0, label.long())\n",
        "        return (feature - centers_batch).pow(2).sum() / 2.0 / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        feature, label, centers, batch_size = ctx.saved_tensors\n",
        "        centers_batch = centers.index_select(0, label.long())\n",
        "        diff = centers_batch - feature\n",
        "        # init every iteration\n",
        "        counts = centers.new_ones(centers.size(0))\n",
        "        ones = centers.new_ones(label.size(0))\n",
        "        grad_centers = centers.new_zeros(centers.size())\n",
        "\n",
        "        counts = counts.scatter_add_(0, label.long(), ones)\n",
        "        grad_centers.scatter_add_(0, label.unsqueeze(1).expand(feature.size()).long(), diff)\n",
        "        grad_centers = grad_centers/counts.view(-1, 1)\n",
        "        return - grad_output * diff / batch_size, None, grad_centers / batch_size, None\n",
        "\n",
        "#Testing function\n",
        "def main(test_cuda=False):\n",
        "    print('-'*80)\n",
        "    device = torch.device(\"cuda\" if test_cuda else \"cpu\")\n",
        "    ct = CenterLoss(10,2,size_average=True).to(device)\n",
        "    y = torch.Tensor([0,0,2,1]).to(device)\n",
        "    feat = torch.zeros(4,2).to(device).requires_grad_()\n",
        "    print (list(ct.parameters()))\n",
        "    \n",
        "    print (ct.centers.grad)\n",
        "    out = ct(y,feat)\n",
        "    print(out.item())\n",
        "    out.backward()\n"
      ],
      "metadata": {
        "id": "5sls623wqzlt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "def test(dataset_name,dataloader, epoch):\n",
        "\n",
        "\n",
        "    cuda = True\n",
        "    cudnn.benchmark = True\n",
        "    alpha = 0\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\" training \"\"\"\n",
        "    model_root='/'\n",
        "    my_net = torch.load(os.path.join(\n",
        "        model_root, 'mnist_mnistm_model_epoch_' + str(epoch) + '.pth'\n",
        "    ))\n",
        "    my_net = my_net.eval()\n",
        "\n",
        "    if cuda:\n",
        "        my_net = my_net.cuda()\n",
        "\n",
        "    len_dataloader = len(dataloader)\n",
        "    data_target_iter = iter(dataloader)\n",
        "\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        # test model using target data\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, t_label = data_target\n",
        "\n",
        "        batch_size = len(t_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 1, 18, 201)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "        if cuda:\n",
        "            t_img = t_img.cuda()\n",
        "            t_label = t_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "        class_label.resize_as_(t_label).copy_(t_label)\n",
        "\n",
        "        _,class_output, _ = my_net(x=input_img, alpha=alpha)\n",
        "        pred = class_output.data.max(1, keepdim=True)[1]\n",
        "        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n",
        "        n_total += batch_size\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
        "\n",
        "    print('epoch: %d, accuracy of the %s dataset: %f' % (epoch, dataset_name, accu),n_correct.data.numpy() ,n_total)\n",
        "    return accu"
      ],
      "metadata": {
        "id": "st9upa7024dG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import random\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "def run(Subject_number):\n",
        "\n",
        "  source_loader,target_loader,test_loader=train(Subject_number)\n",
        " \n",
        "\n",
        "  cuda = True\n",
        "  cudnn.benchmark = True\n",
        "  lr = 1e-3\n",
        "  n_epoch = 500\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  my_net = CNNModel(2)\n",
        "\n",
        "\n",
        "  centerloss = CenterLoss(2, 48).cuda()\n",
        "  optimzer4center = optim.Adam(centerloss.parameters(), lr =0.5)\n",
        "  optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
        "\n",
        "  loss_class = torch.nn.NLLLoss()\n",
        "  loss_domain = torch.nn.NLLLoss()\n",
        "\n",
        "  if cuda:\n",
        "    my_net = my_net.cuda()\n",
        "    loss_class = loss_class.cuda()\n",
        "    loss_domain = loss_domain.cuda()\n",
        "\n",
        "  for p in my_net.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "\n",
        "  source_loader,target_loader,test_loader=train(Subject_number)\n",
        "  dataloader_source=source_loader\n",
        "  dataloader_target=target_loader\n",
        "\n",
        "  model_root = os.path.join('')\n",
        "  trainacc=[]\n",
        "  testacc=[]\n",
        "  targacc=[]\n",
        "  for epoch in range(n_epoch):\n",
        "\n",
        "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
        "    data_source_iter = iter(dataloader_source)\n",
        "    data_target_iter = iter(dataloader_target)\n",
        "\n",
        "    i = 0\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        # training model using source data\n",
        "        data_source = data_source_iter.next()\n",
        "        s_img, s_label = data_source\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        my_net.zero_grad()\n",
        "        batch_size = len(s_label)\n",
        "        input_img = torch.FloatTensor(batch_size, 1, 18, 201)\n",
        "        \n",
        "\n",
        "\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "        domain_label = torch.zeros(batch_size)\n",
        "        domain_label = domain_label.long()\n",
        "\n",
        "        if cuda:\n",
        "            s_img = s_img.cuda()\n",
        "            s_label = s_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "            domain_label = domain_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(s_img).copy_(s_img)\n",
        "        class_label.resize_as_(s_label).copy_(s_label)\n",
        "\n",
        "\n",
        "        _,class_output, domain_output = my_net(x=input_img, alpha=alpha)\n",
        "\n",
        "        err_s_label = loss_class(class_output, class_label)\n",
        "        err_s_domain = loss_domain(domain_output, domain_label)\n",
        "\n",
        "\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, t_label = data_target\n",
        "\n",
        "        batch_size = len(t_img)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "\n",
        "        centerloss.zero_grad()\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 1, 18, 201)\n",
        "        domain_label = torch.ones(batch_size)\n",
        "        domain_label = domain_label.long()\n",
        "\n",
        "        if cuda:\n",
        "            t_img = t_img.cuda()\n",
        "            t_label = t_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "            domain_label = domain_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "        class_label.resize_as_(t_label).copy_(t_label)\n",
        "\n",
        "\n",
        "        fea,class_output, domain_output = my_net(x=input_img, alpha=alpha)\n",
        "\n",
        "        cens=centerloss(class_label, fea)\n",
        "\n",
        "        err_t_label = loss_class(class_output, class_label)\n",
        "        err_t_domain = loss_domain(domain_output, domain_label)\n",
        "        err = err_t_domain + err_s_domain + 10*err_s_label+err_t_label+0.005*cens\n",
        "\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print ('epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
        "        #       % (epoch, i, len_dataloader, err_s_label.cpu().data.numpy(),\n",
        "        #          err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy()))\n",
        "    \n",
        "        i=i+1\n",
        "\n",
        "    torch.save(my_net, '{0}/mnist_mnistm_model_epoch_{1}.pth'.format(model_root, epoch))\n",
        "  traac=test('train',dataloader_source, epoch)\n",
        "  targac=test('target',dataloader_target, epoch)\n",
        "  tesac=test('test',test_loader, epoch)\n"
      ],
      "metadata": {
        "id": "7sI4uZrDtb3I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Subject_number=2\n",
        "run(Subject_number)"
      ],
      "metadata": {
        "id": "Gz069PtUrV7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4b9890-8c4e-41ef-c670-aa36dfae370b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 499, accuracy of the train dataset: 0.800893 897 1120\n",
            "epoch: 499, accuracy of the target dataset: 0.500000 10 20\n",
            "epoch: 499, accuracy of the test dataset: 0.526923 137 260\n"
          ]
        }
      ]
    }
  ]
}